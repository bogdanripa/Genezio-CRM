import fs from 'fs';
import { ChatOpenAI } from '@langchain/openai';
import { OpenApiToolkit } from 'langchain/agents';
import { JsonSpec } from 'langchain/tools';
import { ChatPromptTemplate } from 'langchain/prompts';

async function llmThis() {

    // planner
    const llm = new ChatOpenAI({ modelName: 'gpt-4', temperature: 0, openAIApiKey: process.env.OPENAI_API_KEY, });

    const plannerPrompt = ChatPromptTemplate.fromMessages([
        ['system', 'You are a planner that creates a sequence of API calls to fulfill user requests.'],
        ['human', '{input}'],
    ]);

    const plannerChain = plannerPrompt | llm;

    // end planner


  // Load and parse the OpenAPI specification
  const specContent = fs.readFileSync('./swagger.yaml', 'utf8');
  const jsonSpec = new JsonSpec(specContent);

  // Define any necessary headers for your API
  const headers = {
    'Content-Type': 'application/json',
    // Add additional headers if required
  };

  // Initialize the OpenAPI toolkit with the parsed spec and headers
  const toolkit = new OpenApiToolkit(jsonSpec, llm, headers);

  // Retrieve the tools generated by the toolkit
  const tools = toolkit.getTools();

  // Manually integrate tools with your LLM or agent framework
  // This step will depend on your specific agent implementation
  // For example, you might create a custom agent that utilizes these tools

  // Example: Invoke a tool directly (replace 'toolName' with the actual tool's name)
  const tool = tools.find(t => t.name === 'toolName');
  if (tool) {
    const response = await tool.invoke('Give me the latest on the BCR account.');
    console.log(response);
  } else {
    console.error('Tool not found.');
  }
}

export { llmThis };